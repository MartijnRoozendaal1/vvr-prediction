{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjHNS288y5DHrrUMByUWjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartijnRoozendaal1/vvr-prediction/blob/main/Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setup and Imports"
      ],
      "metadata": {
        "id": "J3U5aZfARLAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AWVlStC8ROmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define Reusable Functions\n"
      ],
      "metadata": {
        "id": "H5OXsr2ZRYTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(feature_path, label_path, feature_size, max_frames=25):\n",
        "    # Load features and labels\n",
        "    features = np.load(feature_path, allow_pickle=True).item()\n",
        "    labels_df = pd.read_csv(label_path)\n",
        "\n",
        "    # Match IDs\n",
        "    features_cleaned = {\n",
        "        int(video_id.split('_')[0].split('-')[0]): feat for video_id, feat in features.items()\n",
        "    }\n",
        "    matching_ids = set(features_cleaned.keys()).intersection(set(labels_df['ID']))\n",
        "    features_matched = {id_: features_cleaned[id_] for id_ in matching_ids}\n",
        "    labels_matched = labels_df[labels_df['ID'].isin(matching_ids)].sort_values(by='ID')\n",
        "\n",
        "    # Pad/truncate features\n",
        "    X = np.array([\n",
        "        np.pad(\n",
        "            features_matched[id_][:max_frames],\n",
        "            ((0, max(0, max_frames - len(features_matched[id_]))), (0, 0)),\n",
        "            mode='constant'\n",
        "        )[:max_frames]\n",
        "        for id_ in labels_matched['ID']\n",
        "    ])\n",
        "    y = np.array(labels_matched['VVR_label'].apply(lambda x: 1 if x == 'High' else 0))\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SSv1NpwQRQ2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Split Data and Apply SMOTE"
      ],
      "metadata": {
        "id": "aP63fqE7RjYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_datasets(X, y, test_size=0.3, batch_size=32):\n",
        "    # Train-test-validation split\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
        "\n",
        "    # Apply SMOTE\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    sm = SMOTE(random_state=seed)\n",
        "    X_train_balanced, y_train_balanced = sm.fit_resample(X_train_flat, y_train)\n",
        "    X_train_balanced = X_train_balanced.reshape(-1, X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_tensor_train = torch.tensor(X_train_balanced, dtype=torch.float32)\n",
        "    y_tensor_train = torch.tensor(y_train_balanced, dtype=torch.float32)\n",
        "    X_tensor_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_tensor_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_tensor_train, y_tensor_train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(TensorDataset(X_tensor_val, y_tensor_val), batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "GHX5A_8iRqEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define Models"
      ],
      "metadata": {
        "id": "07s2tfBJR_mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, rnn_output):\n",
        "        weights = torch.softmax(self.attn(rnn_output), dim=1)\n",
        "        return torch.sum(weights * rnn_output, dim=1)\n",
        "\n",
        "class RNNWithAttention(nn.Module):\n",
        "    def __init__(self, rnn_type, input_size, hidden_size, output_size, num_layers=2, dropout=0.3):\n",
        "        super(RNNWithAttention, self).__init__()\n",
        "        if rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
        "        elif rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid rnn_type. Choose either 'GRU' or 'LSTM'.\")\n",
        "\n",
        "        self.attention = Attention(hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        attended_output = self.attention(rnn_output)\n",
        "        return self.fc(attended_output)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Y7M67FESB3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train Model"
      ],
      "metadata": {
        "id": "7KBs2rMwSIjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50, patience=5):\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch).squeeze()\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                outputs = model(X_batch).squeeze()\n",
        "                val_loss += criterion(outputs, y_batch).item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n"
      ],
      "metadata": {
        "id": "Msuaj4mnSH_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Load Data"
      ],
      "metadata": {
        "id": "bvuLAozSST7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to data\n",
        "resnet_features_path = '/content/drive/MyDrive/ResNet152_Features.npy'\n",
        "vgg_features_path = '/content/drive/MyDrive/VGG16_Features_512.npy'\n",
        "labels_path = '/content/drive/MyDrive/time_points_binary_labels.csv'\n",
        "\n",
        "# Choose features\n",
        "use_features = 'ResNet'  # Options: 'ResNet' or 'VGG'\n",
        "\n",
        "if use_features == 'ResNet':\n",
        "    X, y = load_data(resnet_features_path, labels_path, feature_size=2048)\n",
        "elif use_features == 'VGG':\n",
        "    X, y = load_data(vgg_features_path, labels_path, feature_size=512)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fyN7IOLySXrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Prepare Datasets"
      ],
      "metadata": {
        "id": "i9F04bbQSf-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader = prepare_datasets(X, y, batch_size=32 if use_features == 'ResNet' else 8)\n"
      ],
      "metadata": {
        "id": "M_SERxhISjrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Initialize and Train Models"
      ],
      "metadata": {
        "id": "MeAMieobSm2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GRU and LSTM models\n",
        "hidden_size, output_size = 128, 1\n",
        "gru_model = RNNWithAttention('GRU', input_size=X.shape[2], hidden_size=hidden_size, output_size=output_size)\n",
        "lstm_model = RNNWithAttention('LSTM', input_size=X.shape[2], hidden_size=hidden_size, output_size=output_size)\n",
        "\n",
        "gru_optimizer = optim.Adam(gru_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train models\n",
        "print(f\"Training GRU model with {use_features} features...\")\n",
        "train_model(gru_model, train_loader, val_loader, criterion, gru_optimizer)\n",
        "\n",
        "print(f\"Training LSTM model with {use_features} features...\")\n",
        "train_model(lstm_model, train_loader, val_loader, criterion, lstm_optimizer)\n"
      ],
      "metadata": {
        "id": "d8jN7VqbSpXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}